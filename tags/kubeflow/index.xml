<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubeflow on Kubermates</title><link>https://kubermates.org/tags/kubeflow/</link><description>Recent content in Kubeflow on Kubermates</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 21 Jul 2025 00:00:00 -0500</lastBuildDate><atom:link href="https://kubermates.org/tags/kubeflow/index.xml" rel="self" type="application/rss+xml"/><item><title>Democratizing AI Model Training on Kubernetes: Introducing Kubeflow Trainer V2</title><link>https://kubermates.org/docs/2025-07-21-democratizing-ai-model-training-on-kubernetes-introducing-kubeflow-trainer-v2/</link><pubDate>Mon, 21 Jul 2025 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2025-07-21-democratizing-ai-model-training-on-kubernetes-introducing-kubeflow-trainer-v2/</guid><description>Jul 21, 2025 • Kubeflow Trainer Team • 11 min read trainer Running machine learning workloads on Kubernetes can be challenging. Distributed training and LLMs fine-tuning, in particular, involves managing multiple nodes, GPUs, large datasets, and fault tolerance, which often requires deep Kubernetes knowledge. The Kubeflow Trainer v2 (KF Trainer) was created to hide this complexity, by abstracting Kubernetes from AI Practitioners and providing the easiest, most scalable way to run distributed PyTorch jobs. The main goals of Kubeflow Trainer v2 include: We’re deeply grateful to all contributors and community members who made the Trainer v2 possible with their hard work and valuable feedback. We’d like to give special recognition to andreyvelich , tenzen-y , electronic-waste , astefanutti , ironicbo , mahdikhashan , kramaranya , harshal292004 , akshaychitneni , chenyi015 and the rest of the contributors. We would also like to highlight ahg-g , kannon92 , and vsoch whose feedback was essential while we designed the Kubeflow Trainer architecture together with the Batch WG. See the full contributor list for everyone who helped make this release possible. Kubeflow Trainer v2 represents the next evolution of the Kubeflow Training Operator , building on over seven years of experience running ML workloads on Kubernetes. The journey began in 2017 when the Kubeflow project introduced TFJob to orchestrate TensorFlow training on Kubernetes. At that time, Kubernetes lacked many of the advanced batch processing features needed for distributed ML training, so the community had to implement these capabilities from scratch. Over the years, the project expanded to support multiple ML frameworks including PyTorch , MXNet , MPI , and XGBoost through various specialized operators. In 2021, these were consolidated into the unified Training Operator v1.</description></item><item><title>From Raw Data to Model Serving: A Blueprint for the AI/ML Lifecycle with Kubeflow</title><link>https://kubermates.org/docs/2025-07-15-from-raw-data-to-model-serving-a-blueprint-for-the-ai-ml-lifecycle-with-kubeflow/</link><pubDate>Tue, 15 Jul 2025 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2025-07-15-from-raw-data-to-model-serving-a-blueprint-for-the-ai-ml-lifecycle-with-kubeflow/</guid><description>Jul 15, 2025 • Helber Belmiro • 22 min read mlops pipelines spark feast model-registry kserve Are you looking for a practical, reproducible way to take a machine learning project from raw data all the way to a deployed, production-ready model? This post is your blueprint for the AI/ML lifecycle: you’ll learn how to use Kubeflow and open source tools such as Feast to build a workflow you can run on your laptop and adapt to your own projects. We’ll walk through the entire ML lifecycle—from data preparation to live inference—leveraging the Kubeflow platform to create a cohesive, production-grade MLOps workflow. The project implements a complete MLOps workflow for a fraud detection use case. Fraud detection is a critical application in financial services, where organizations need to identify potentially fraudulent transactions in real-time while minimizing false positives that could disrupt legitimate customer activity. Our fraud detection system leverages machine learning to analyze large volumes of transaction data, learn patterns from historical behavior, and flag suspicious transactions that deviate from normal patterns. The model considers various features such as transaction amounts, location data, merchant information, and user behavior patterns to make predictions. This makes fraud detection an ideal use case for demonstrating MLOps concepts because it requires: The workflow ingests raw transaction data, proceeds through data preparation and feature engineering, then model training and registration, and finally deploys the model as a production-ready inference service that can evaluate transactions in real-time. The entire workflow is orchestrated as a Kubeflow Pipeline, which provides a powerful framework for defining, deploying, and managing complex machine learning pipelines on Kubernetes. Here is a high-level overview of the pipeline: The pipeline assumes that the initial datasets ( train. csv , test. csv , etc. ) are already available.</description></item><item><title>Kubeflow 1.10 Release Announcement</title><link>https://kubermates.org/docs/2025-03-26-kubeflow-1-10-release-announcement/</link><pubDate>Wed, 26 Mar 2025 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2025-03-26-kubeflow-1-10-release-announcement/</guid><description>Mar 26, 2025 • Kubeflow 1. 10 Release Team, Dimitris Poulopoulos • 8 min read release Kubeflow 1. 10. 0 delivers essential updates that enhance the flexibility, efficiency, and scalability of machine learning workflows. The new features span across several components, improving both user experience and system performance. The Kubeflow Platform Working Group focuses on simplifying Kubeflow installation, operations, and security. See details below. Trivy CVE scans March 25 2025: Kubeflow Pipelines 2. 4. 1 introduces support for placeholders in resource limits , enhancing flexibility in pipeline execution. This update allows users to define dynamic resource limits using parameterized values, enabling more adaptable and reusable pipeline definitions. Kubeflow Pipelines 2.</description></item><item><title>🚀 Announcing the Kubeflow Spark Operator Benchmarking Results</title><link>https://kubermates.org/docs/2025-03-15-announcing-the-kubeflow-spark-operator-benchmarking-results/</link><pubDate>Sat, 15 Mar 2025 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2025-03-15-announcing-the-kubeflow-spark-operator-benchmarking-results/</guid><description>Mar 15, 2025 • Vara Bonthu , Manabu McCloskey , Ratnopam Chakrabarti , Alan Halcyon • 5 min read operators benchmarking performance Kubernetes has become the go-to platform for running large-scale Apache Spark workloads. But as workloads scale, how do you ensure your Spark jobs run efficiently without hitting bottlenecks? Managing thousands of concurrent Spark jobs can introduce severe performance challenges —from CPU saturation in the Spark Operator to Kubernetes API slowdowns and job scheduling inefficiencies. To address these challenges, we are excited to introduce the Kubeflow Spark Operator Benchmarking Results and Toolkit —a comprehensive framework to analyze performance, pinpoint bottlenecks, and optimize your Spark on Kubernetes deployments. This benchmarking effort provides three key outcomes to help you take full control of your Spark on Kubernetes deployment: ✅ Benchmarking Results – A detailed evaluation of performance insights and tuning recommendations for large-scale Spark workloads. 🛠 Benchmarking Test Toolkit – A fully reproducible test suite to help users evaluate their own Spark Operator performance and validate improvements. 📊 Open-Sourced Grafana Dashboard – A battle-tested visualization tool designed specifically to track large-scale Spark Operator deployments, providing real-time monitoring of job processing efficiency, API latencies, and system health. Running thousands of Spark jobs on Kubernetes at scale uncovers several performance roadblocks that can cripple efficiency if left unresolved: 💡 So, how do you fix these issues and optimize your Spark Operator deployment? That’s where our benchmarking results and toolkit come in. Based on our benchmarking findings, we provide clear, actionable recommendations for improving Spark Operator performance at scale. If you’re running thousands of concurrent Spark jobs , here’s what you need to do: 💡 Why? A single Spark Operator instance struggles to keep up with high job submission rates. ✅ Solution : When a single Spark Operator instance struggles with high job submission rates, leading to CPU saturation and slower job launches, deploying multiple instances can help. Distribute the workload by assigning different namespaces to each instance. For example, one instance can manage ` 20 namespaces while another handles a separate set of 20 namespaces.</description></item><item><title>Optimizing RAG Pipelines with Katib: Hyperparameter Tuning for Better Retrieval &amp;amp; Generation</title><link>https://kubermates.org/docs/2025-02-21-optimizing-rag-pipelines-with-katib-hyperparameter-tuning-for-better-retrieval-a/</link><pubDate>Fri, 21 Feb 2025 00:00:00 -0600</pubDate><guid>https://kubermates.org/docs/2025-02-21-optimizing-rag-pipelines-with-katib-hyperparameter-tuning-for-better-retrieval-a/</guid><description>Leveraging Katib for efficient RAG optimization. Feb 21, 2025 • Varsha Prasad Narsing (@varshaprasad96) • 7 min read katib As artificial intelligence and machine learning models become more sophisticated, optimising their performance remains a critical challenge. Kubeflow provides a robust component, Katib , designed for hyperparameter optimization and neural architecture search. As a part of the Kubeflow ecosystem, Katib enables scalable, automated tuning of underlying machine learning models, reducing the manual effort required for parameter selection while improving model performance across diverse ML workflows. With Retrieval-Augmented Generation ( RAG ) becoming an increasingly popular approach for improving search and retrieval quality, optimizing its parameters is essential to achieving high-quality results. RAG pipelines involve multiple hyperparameters that influence retrieval accuracy, hallucination reduction, and language generation quality. In this blog, we will explore how Katib can be leveraged to fine-tune a RAG pipeline, ensuring optimal performance by systematically adjusting key hyperparameters. Since compute resources are scarcer than a perfectly labeled dataset :), we’ll use a lightweight Kind cluster (Kubernetes in Docker) cluster to run this example locally. Rest assured, this setup can seamlessly scale to larger clusters by increasing the dataset size and the number of hyperparameters to tune. To get started, we’ll first install the Katib control plane in our cluster by following the steps outlined in the documentation. In this implementation, we use a retriever model , which encodes queries and documents into vector representations to find the most relevant matches, to fetch relevant documents based on a query and a generator model to produce coherent text responses. To run Katib, we will use the Katib SDK , which provides a programmatic interface for defining and running hyperparameter tuning experiments in Kubeflow.</description></item><item><title>Synthetic Data Generation with Kubeflow Pipelines</title><link>https://kubermates.org/docs/2025-02-16-synthetic-data-generation-with-kubeflow-pipelines/</link><pubDate>Sun, 16 Feb 2025 00:00:00 -0600</pubDate><guid>https://kubermates.org/docs/2025-02-16-synthetic-data-generation-with-kubeflow-pipelines/</guid><description>Feb 16, 2025 • Åke Edlund , Tarek Abouzeid • 11 min read kfp When creating insights, decisions, and actions from data, the best results come from real data. But accessing real data often requires lengthy security and legal processes. The data may also be incomplete, biased, or too small, and during early exploration, we may not even know if it’s worth pursuing. While real data is essential for proper evaluation, gaps or limited access frequently hinder progress until the formal process is complete. To address these challenges, synthetic data provides an alternative. It mimics real data’s statistical properties while preserving privacy and accessibility. Synthetic data generators (synthesizers) are models trained on real data to generate new datasets that follow the same statistical distributions and relationships but do not contain real records. This allows for accelerated development, improved data availability, and enhanced privacy. Depending on the technique used, synthetic data not only mirrors statistical base properties of real data but also preserves correlations between features. These synthesizers — such as those based on Gaussian Copulas, Generative Adversarial Networks (GANs), and Variational Autoencoders (VAEs) — enable the creation of high-fidelity synthetic datasets. See more description of these techniques below. While the above focuses on speed of development in general, and augmentation of data to improve performance of analytical modes, there are more motivations for creating (synthetic) data: Enhanced Privacy and Security Mimics real datasets without containing sensitive or personally identifiable information, mitigating privacy risks and ensuring compliance with regulations like GDPR.</description></item><item><title>Kubeflow and Me: A Story Started with Push-based Metrics Collection</title><link>https://kubermates.org/docs/2024-09-28-kubeflow-and-me-a-story-started-with-push-based-metrics-collection/</link><pubDate>Sat, 28 Sep 2024 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2024-09-28-kubeflow-and-me-a-story-started-with-push-based-metrics-collection/</guid><description>Sep 28, 2024 • Shao Wang(Electronic-Waste) • 4 min read gsoc This summer, I gained a precious opportunity to participate in the Google Summer of Code(GSoC), in which I would contribute to Katib and fulfill a project named “Push-based Metrics Collection in Katib” within 12 weeks. Firstly, I got to know about GSoC and Kubeflow with the recommendation from the former active maintainer Ce Gao(gaocegege)’s personal blog. And I was deeply impressed by the idea of cloud native AI toolkits, I decided to dive into this area and learn some skills to enhance my career and future. In the blog, I’ll provide my personal insight into Katib, for those who are interested in cloud native, AI, and hyperparameters tuning. The project aims to provide a Python SDK API interface for users to push metrics to Katib DB directly. The current implementation of Metrics Collector is pull-based, raising design problems such as determining the frequency at which we scrape the metrics, performance issues like the overhead caused by too many sidecar containers, and restrictions on developing environments that must support sidecar containers and admission webhooks. And also, for data scientists, they need to pay attention to the format of metrics printed in the training scripts, which is error prone and may be hard to recognize. We decided to implement a new API for Katib Python SDK to offer users a push-based way to store metrics directly into the Kaitb DB and resolve those issues raised by pull-based metrics collection. In the new design, users just need to set metrics_collector_config={&amp;ldquo;kind&amp;rdquo;: &amp;ldquo;Push&amp;rdquo;} in the tune() function and call the report_metrics() API in their objective function to push metrics to Katib DB directly. There are no sidecar containers and restricted metric log formats any more. After that, Trial Controller will continuously collect metrics from Katib DB and update the status of Trial, which is the same as pull-based metrics collection. If you are interested in it, please refer to this doc and example for more details.</description></item><item><title>LLM Hyperparameter Optimization API: My Google Summer of Code Journey with Kubeflow</title><link>https://kubermates.org/docs/2024-09-19-llm-hyperparameter-optimization-api-my-google-summer-of-code-journey-with-kubefl/</link><pubDate>Thu, 19 Sep 2024 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2024-09-19-llm-hyperparameter-optimization-api-my-google-summer-of-code-journey-with-kubefl/</guid><description>Sep 19, 2024 • Hezhi(Helen) Xie • 4 min read gsoc This summer, I had the opportunity to participate in the Google Summer of Code (GSoC) program, where I contributed to Kubeflow, an open-source machine learning toolkit. My project focused on developing a high-level API for optimizing hyperparameters in Large Language Models (LLMs) within Katib, Kubeflow’s automated hyperparameter tuning system. I’d like to share insights from this experience with others interested in Kubeflow, GSoC, or optimizing LLMs. The rapid advancements and rising popularity of LLMs, such as GPT and BERT, have created a growing demand for efficient LLMOps in Kubernetes. To address this, we have developed a train API within the Training Python SDK, simplifying the process of fine-tuning LLMs using distributed PyTorchJob workers. However, hyperparameter optimization remains a crucial yet labor-intensive task for enhancing model performance. Hyperparameter optimization is essential but time-consuming, especially for LLMs with billions of parameters. This API simplifies the process by handling Kubernetes infrastructure, allowing data scientists to focus on model performance rather than system configuration. With this API, users can import pretrained models and datasets from Hugging Face and Amazon S3, define parameters including the hyperparameter search space, optimization objective, and resource configuration. The API then automates the creation of Experiment, which contains multiple Trials with different hyperparameter settings using PyTorch distributed training. It then collects and analyzes the metrics from each Trial to identify the optimal hyperparameter configuration. For detailed instruction on using the API, please refer to this guide My work on the project can be broadly divided into four stages: In addition, I addressed several critical bugs in previous Katib and Training Operator releases and contributed new features, such as writing end-to-end tests for the train API.</description></item><item><title>Kubeflow 1.9: New Tools for Model Management and Training Optimization</title><link>https://kubermates.org/docs/2024-07-22-kubeflow-1-9-new-tools-for-model-management-and-training-optimization/</link><pubDate>Mon, 22 Jul 2024 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2024-07-22-kubeflow-1-9-new-tools-for-model-management-and-training-optimization/</guid><description>Jul 22, 2024 • Kubeflow 1. 9 Release Team, Stefano Fioravanzo • 11 min read release Kubeflow 1. 9 significantly simplifies the development, tuning and management of secure machine learning models and LLMs. Highlights include: These updates aim to simplify workflows, improve integration dependencies, and provide Kubernetes-native operational efficiencies for enterprise scale, security, and isolation. A model registry provides a central catalog for ML model developers to index and manage models, versions, and ML artifacts metadata. It fills a gap between model experimentation and production activities. It provides a central interface for all stakeholders in the ML lifecycle to collaborate on ML models. Model registry has been asked by the community for a long time and we are delighted to introduce it to the Kubeflow ecosystem. This initial release includes REST APIs and a Python SDK to track model artifacts and model metadata with a standardized format that can be reused across Kubeflow components, such as to deploy Inference Servers. You can get started by following the Model Registry tutorial on the Kubeflow website , or see a short demo video of the Model Registry in action. We are just getting started. This is an Alpha version and we look forward to feedback.</description></item><item><title>Announcing the Kubeflow Spark Operator: Building a Stronger Spark on Kubernetes Community</title><link>https://kubermates.org/docs/2024-04-15-announcing-the-kubeflow-spark-operator-building-a-stronger-spark-on-kubernetes-c/</link><pubDate>Mon, 15 Apr 2024 00:00:00 -0500</pubDate><guid>https://kubermates.org/docs/2024-04-15-announcing-the-kubeflow-spark-operator-building-a-stronger-spark-on-kubernetes-c/</guid><description>Apr 15, 2024 • Vara Bonthu , Chaoran Yu , Andrey Velichkevich , Marcin Wielgus • 4 min read operators We’re excited to announce the migration of Google’s Spark Operator to the Kubeflow Spark Operator , marking the launch of a significant addition to the Kubeflow ecosystem. The Kubeflow Spark Operator simplifies the deployment and management of Apache Spark applications on Kubernetes. This announcement isn’t just about a new piece of technology, it’s about building a stronger, open-governed, and more collaborative community around Spark on Kubernetes. The journey of the Kubeflow Spark Operator began with Google Cloud Platform’s Spark on Kubernetes Operator (https://cloud. google. com/blog/products/data-analytics/data-analytics-meet-containers-kubernetes-operator-for-apache-spark-now-in-beta). With over 2. 3k stars and 1. 3k forks on GitHub, this project laid the foundation for a robust Spark on Kubernetes experience, enabling users to deploy Spark workloads seamlessly across Kubernetes clusters. Growth and innovation require not just code but also community. Acknowledging the resource and time limitations faced by Google Cloud’s original maintainers, Kubeflow has taken up the mantle. This transition is not merely administrative but a strategic move towards fostering a vibrant, diverse, and more actively engaged community.</description></item></channel></rss>